{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lph-LbYMbsH"
      },
      "source": [
        "# Redes neuronales artificiales utilizando Scikit-Learn\n",
        "\n",
        "La clase MLPClassifier implementa un algoritmo de perceptrón multicapa (MLP) que se entrena utilizando Retropropagación (Backpropagation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los parámetros más interesantes a la hora de definir una red neuronal utilizando  [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) son:\n",
        "\n",
        "* **Para la estructura de la red:**\n",
        "\n",
        "    * hidden_layer_sizes: con este parámetro definimos la numero de capas y el número de nodos que queremos. Cada elemento en la tupla representa el numero de nodos en la iesima posición, donde el indice corresponde al de su posición en la tupla. Por ejemplo, el parámetro (5,2) define dos capas, la primera tendrá 5 nodos y la segunda 2 nodos. \n",
        "\n",
        "* **Funciones de activación:**\n",
        "  * activation: define la función de activación para las capas ocultas. Los posibles valores son: {‘identity’ sin transformación (lineal), ‘logistic’ (función sigmoide), ‘tanh’ (tangente hiperbólica), ‘relu’ (rectified Linear Unit)}, default=’relu’\n",
        "\n",
        "* **Algoritmo de optimización:**\n",
        "\n",
        "  * solver: indica el algoritmo de optimización. Los posibles valores son: {‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’\n",
        "\n",
        "* **Tasa de aprendizaje:**\n",
        "  \n",
        "  * learning_rate: Cómo se ajustan los pesos durante el entrenamiento.\n",
        "    * 'constant': Fijo.\n",
        "    * 'invscaling': Decrece con las iteraciones.\n",
        "    * 'adaptive': Se ajusta según la validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8R-5ebMvI4Ph"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "X, y = make_classification(n_samples=400, random_state=42, n_classes=2) #genero el dataset con 400 muestras y 2 clases\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
        "                                                    random_state=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generación de redes neuronales para problemas de clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Definición de la estructura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf = MLPClassifier(hidden_layer_sizes=(150,100,50),\n",
        "                        activation = 'relu',\n",
        "                        solver = 'adam',\n",
        "                        learning_rate='adaptive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Posteriormente se puede entrenar el modelo utilizando la función `fit(x,y)` donde `x` corresponde a los datos de entrada e `y` corresponde al target value.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(150, 100, 50), learning_rate=&#x27;adaptive&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(150, 100, 50), learning_rate=&#x27;adaptive&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=(150, 100, 50), learning_rate='adaptive')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análisis de la red neuronal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez entrenado el modelo podemos acceder a información por medio de diferentes atributos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "0.001314218841592306\n",
            "[array([[ 0.0582447 ,  0.05026171,  0.0859854 , ..., -0.07727536,\n",
            "        -0.02710259, -0.07718382],\n",
            "       [-0.09241211,  0.02688664, -0.05187178, ...,  0.04316804,\n",
            "         0.07768852, -0.11101593],\n",
            "       [ 0.1143678 , -0.07367388,  0.10816706, ..., -0.07867884,\n",
            "         0.01295381,  0.18977639],\n",
            "       ...,\n",
            "       [ 0.12763847,  0.17215396,  0.1523791 , ...,  0.04050622,\n",
            "         0.1898287 , -0.02534187],\n",
            "       [-0.02899205,  0.05921173, -0.01601822, ..., -0.13166828,\n",
            "         0.15584755,  0.02750063],\n",
            "       [-0.21196018,  0.07444649, -0.04007293, ..., -0.10194837,\n",
            "         0.12602327,  0.206509  ]]), array([[-0.08913741,  0.16813956, -0.03133981, ..., -0.12589116,\n",
            "         0.07970647, -0.03291654],\n",
            "       [-0.07342179,  0.08982486, -0.00748123, ...,  0.03703566,\n",
            "         0.04034721,  0.09205264],\n",
            "       [ 0.05435174,  0.13008776, -0.02489583, ...,  0.14996452,\n",
            "        -0.05394787, -0.12487916],\n",
            "       ...,\n",
            "       [-0.03845712,  0.08773875,  0.11173468, ...,  0.09411065,\n",
            "         0.1648077 , -0.11116533],\n",
            "       [-0.05322511,  0.15362424, -0.06443551, ...,  0.0804047 ,\n",
            "         0.10798946, -0.01996813],\n",
            "       [-0.00561995, -0.00730635, -0.0923128 , ..., -0.09057489,\n",
            "        -0.10000827, -0.0069479 ]]), array([[-0.15275285, -0.07482005, -0.03508722, ...,  0.23970548,\n",
            "        -0.04761835, -0.12926236],\n",
            "       [ 0.15398342,  0.17622671,  0.00880195, ...,  0.24657395,\n",
            "         0.02258291, -0.06749895],\n",
            "       [ 0.14816772,  0.07387578, -0.0821607 , ..., -0.0513459 ,\n",
            "        -0.06688939,  0.01401173],\n",
            "       ...,\n",
            "       [-0.07366508,  0.07702347,  0.00255155, ...,  0.11612874,\n",
            "         0.23929894,  0.15989115],\n",
            "       [-0.13255651, -0.05138205, -0.01170833, ...,  0.04163127,\n",
            "         0.09052882,  0.10100215],\n",
            "       [-0.19726051,  0.10197939, -0.1333572 , ..., -0.04208116,\n",
            "        -0.15615688, -0.05108054]]), array([[-0.25704998],\n",
            "       [ 0.14717049],\n",
            "       [-0.04455265],\n",
            "       [ 0.19013164],\n",
            "       [-0.26840026],\n",
            "       [-0.18677439],\n",
            "       [-0.27267759],\n",
            "       [-0.19757709],\n",
            "       [-0.17579876],\n",
            "       [ 0.2003015 ],\n",
            "       [-0.07907097],\n",
            "       [-0.26421178],\n",
            "       [-0.36067469],\n",
            "       [ 0.34702067],\n",
            "       [-0.37586144],\n",
            "       [ 0.23423989],\n",
            "       [-0.05276094],\n",
            "       [-0.23762604],\n",
            "       [ 0.28203121],\n",
            "       [-0.37251922],\n",
            "       [-0.23653977],\n",
            "       [-0.37881966],\n",
            "       [ 0.10319032],\n",
            "       [ 0.32522333],\n",
            "       [ 0.13308223],\n",
            "       [-0.41607428],\n",
            "       [ 0.27208407],\n",
            "       [-0.19108291],\n",
            "       [-0.05401458],\n",
            "       [-0.24657701],\n",
            "       [ 0.26986553],\n",
            "       [ 0.25945481],\n",
            "       [-0.09499547],\n",
            "       [-0.09920161],\n",
            "       [-0.36979205],\n",
            "       [-0.21216062],\n",
            "       [-0.13063102],\n",
            "       [-0.27278363],\n",
            "       [-0.31791823],\n",
            "       [-0.0859134 ],\n",
            "       [-0.22168599],\n",
            "       [-0.06723434],\n",
            "       [ 0.31731668],\n",
            "       [ 0.22947499],\n",
            "       [-0.35186876],\n",
            "       [-0.16413264],\n",
            "       [-0.1317185 ],\n",
            "       [ 0.3129773 ],\n",
            "       [ 0.34662366],\n",
            "       [-0.41740796]])]\n",
            "5\n",
            "1\n",
            "logistic\n"
          ]
        }
      ],
      "source": [
        "#posibles clases a las que puede pertenecer\n",
        "print(clf.classes_)\n",
        "\n",
        "#valor de la función de perdida\n",
        "print(clf.loss_)\n",
        "\n",
        "#lista con los coeficientes de los pesos de las capas\n",
        "print(clf.coefs_)\n",
        "\n",
        "#numero de capas\n",
        "print(clf.n_layers_)\n",
        "\n",
        "#numero de outputs\n",
        "print(clf.n_outputs_)\n",
        "\n",
        "#nombre de la función de activación de la última capa\n",
        "print(clf.out_activation_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predicción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Después del ajuste (entrenamiento), el modelo puede predecir las etiquetas para nuevas muestras de diferentes formas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La primera forma es por medio del método `predict_proba`. El método `predict_proba` se utiliza para obtener las probabilidades de pertenencia a cada clase para las muestras proporcionadas. \n",
        "\n",
        "Al ejecutar `clf.predict_proba(X_test[:1])`, el modelo devuelve un array de probabilidades. \n",
        "Cada elemento del array representa la probabilidad de que la muestra pertenezca a una de las clases posibles. \n",
        "Por ejemplo, si el modelo es un clasificador binario, el array tendrá dos valores: \n",
        "la probabilidad de que la muestra pertenezca a la clase 0 y la probabilidad de que pertenezca a la clase 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[2.55943126e-04, 9.99744057e-01],\n",
              "       [9.99936736e-01, 6.32639783e-05]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.predict_proba(X_test[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sin embargo, la función `predict` devolverá la clase sobre la que tiene más probabilidad de pertenecer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 0]\n"
          ]
        }
      ],
      "source": [
        "print(clf.predict(X_test[:2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ejemplo completo dataset iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión: 1.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/csadan/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Cargar datos\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Dividir datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', max_iter=500, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Evaluación\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Precisión: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generación de redes neuronales para problemas de regresión\n",
        "\n",
        "Es posible entrenar un modelo de regresión utilizando la clase MLPRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error cuadrático medio: 55.86\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/csadan/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:684: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Crear un conjunto de datos de regresión\n",
        "X, y = make_regression(n_samples=200, n_features=5, noise=0.1, random_state=42)\n",
        "\n",
        "# Dividir datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear y entrenar el modelo\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(50, 30), \n",
        "                   activation='relu', \n",
        "                   solver='adam', \n",
        "                   max_iter=500, \n",
        "                   random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Evaluación\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Error cuadrático medio: {mse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inclusión del modelo dentro de un pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión: 1.00\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Cargar datos\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Escalador para normalizar los datos\n",
        "    ('mlp', MLPClassifier(max_iter=10000, random_state=42))  # Modelo\n",
        "])\n",
        "\n",
        "# Entrenar el modelo con el pipeline\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluación\n",
        "accuracy = pipeline.score(X_test, y_test)\n",
        "print(f\"Precisión: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "También se podría hacer para un modelo de regresión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error cuadrático medio: 8.16\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Crear un conjunto de datos de regresión\n",
        "X, y = make_regression(n_samples=200, n_features=5, noise=0.1, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Escalador\n",
        "    ('mlp', MLPRegressor(max_iter=10000, random_state=42))  # Modelo\n",
        "])\n",
        "\n",
        "# Entrenar el modelo\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Predicción y evaluación\n",
        "y_pred = pipeline.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Error cuadrático medio: {mse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluar el modelo con cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precisión por fold: [1.         0.96666667 0.86666667 1.         0.9       ]\n",
            "Precisión media: 0.95\n",
            "Desviación estándar: 0.05\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Cargar datos\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Crear el pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),  # Escalador\n",
        "    ('mlp', MLPClassifier(max_iter=10000, random_state=42))  # Modelo\n",
        "])\n",
        "\n",
        "# Aplicar validación cruzada\n",
        "cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
        "scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "# Resultados\n",
        "print(\"Precisión por fold:\", scores)\n",
        "print(f\"Precisión media: {scores.mean():.2f}\")\n",
        "print(f\"Desviación estándar: {scores.std():.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
