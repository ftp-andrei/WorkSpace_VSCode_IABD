{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9Wyg-uIlAjJ"
   },
   "source": [
    "# Descargar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3442,
     "status": "ok",
     "timestamp": 1682090742547,
     "user": {
      "displayName": "Carlos Sáenz Adán",
      "userId": "03415872180739491893"
     },
     "user_tz": -120
    },
    "id": "al8Ifa82lCkq",
    "outputId": "f24e9710-b9b7-448a-c726-0864e585d139"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Local\\Temp\\ipykernel_7744\\3826882912.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 39, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Local\\Temp\\ipykernel_7744\\3826882912.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\dtypes\\dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Local\\Temp\\ipykernel_7744\\3826882912.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 50, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\ops\\array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\computation\\check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\site-packages\\numexpr\\__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Local\\Temp\\ipykernel_7744\\3826882912.py\", line 2, in <module>\n",
      "    import pandas as pd\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\__init__.py\", line 62, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\arrow\\array.py\", line 64, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\arrays\\masked.py\", line 60, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"C:\\Users\\Vespertino\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\compat\\_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"c:\\Users\\Vespertino\\anaconda3\\Lib\\site-packages\\bottleneck\\__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\numpy\\core\\_multiarray_umath.py:44\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     46\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.0.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vespertino\\AppData\\Local\\Temp\\ipykernel_7744\\3826882912.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train['salary_currency'].replace(currency, np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Libraries to handle data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Carga del fichero en Python\n",
    "df_train = pd.read_csv('db_salarios.csv', delimiter=',')\n",
    "\n",
    "\n",
    "## se modifica el dataset para que incluya valores nulos\n",
    "currency = ['AUD', 'SGD', 'GBP','BRL', 'PLN', 'CHF','HUF', 'DKK', 'JPY', 'TRY', 'THB', 'ILS', 'HKD', 'CZK', 'MXN', 'CLP']\n",
    "df_train['salary_currency'].replace(currency, np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMH6sBqrN3Jx"
   },
   "source": [
    "## Ejercicio 1. Identifica el número de ocurrencias (0.5 puntos)\n",
    "\n",
    "\n",
    "\n",
    "1.   Muestra el número de ocurrencias de cada uno de los valores de work_year y company_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1682090742548,
     "user": {
      "displayName": "Carlos Sáenz Adán",
      "userId": "03415872180739491893"
     },
     "user_tz": -120
    },
    "id": "QHokKNxycwpW",
    "outputId": "6cee76fa-fc12-477a-c13f-d13273c568af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_year\n",
      "2023    1785\n",
      "2022    1664\n",
      "2021     230\n",
      "2020      76\n",
      "Name: count, dtype: int64\n",
      "company_size\n",
      "M    3153\n",
      "L     454\n",
      "S     148\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el número de ocurrencias de cada uno de los valores de work_year y company_size\n",
    "print(df_train['work_year'].value_counts())\n",
    "print(df_train['company_size'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Muestra cuántos tipos diferentes de trabajos hay, indicados por la columna 'job_title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tipos diferentes de trabajos: 93\n"
     ]
    }
   ],
   "source": [
    "#print('job_title: ',df_train['job_title'].values)\n",
    "\n",
    "# Número de tipos diferentes de trabajos (valores únicos en 'job_title')\n",
    "num_unique_job_titles = df_train['job_title'].nunique()\n",
    "print(f\"Número de tipos diferentes de trabajos: {num_unique_job_titles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNA-U8FwmuY8"
   },
   "source": [
    "## Ejercicio 2. Mostrar información del dataset (1 punto)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.   Mostrar las primeras 10 filas del dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1682090742551,
     "user": {
      "displayName": "Carlos Sáenz Adán",
      "userId": "03415872180739491893"
     },
     "user_tz": -120
    },
    "id": "qiCS5O7_1Kzk",
    "outputId": "7ef23127-d7af-4ea3-b00c-5cf8a8e2e5c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>80000</td>\n",
       "      <td>EUR</td>\n",
       "      <td>85847</td>\n",
       "      <td>ES</td>\n",
       "      <td>100</td>\n",
       "      <td>ES</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>30000</td>\n",
       "      <td>USD</td>\n",
       "      <td>30000</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>ML Engineer</td>\n",
       "      <td>25500</td>\n",
       "      <td>USD</td>\n",
       "      <td>25500</td>\n",
       "      <td>US</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>175000</td>\n",
       "      <td>USD</td>\n",
       "      <td>175000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>120000</td>\n",
       "      <td>USD</td>\n",
       "      <td>120000</td>\n",
       "      <td>CA</td>\n",
       "      <td>100</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Applied Scientist</td>\n",
       "      <td>222200</td>\n",
       "      <td>USD</td>\n",
       "      <td>222200</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Applied Scientist</td>\n",
       "      <td>136000</td>\n",
       "      <td>USD</td>\n",
       "      <td>136000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>219000</td>\n",
       "      <td>USD</td>\n",
       "      <td>219000</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>141000</td>\n",
       "      <td>USD</td>\n",
       "      <td>141000</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>147100</td>\n",
       "      <td>USD</td>\n",
       "      <td>147100</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type                 job_title  \\\n",
       "0       2023               SE              FT  Principal Data Scientist   \n",
       "1       2023               MI              CT               ML Engineer   \n",
       "2       2023               MI              CT               ML Engineer   \n",
       "3       2023               SE              FT            Data Scientist   \n",
       "4       2023               SE              FT            Data Scientist   \n",
       "5       2023               SE              FT         Applied Scientist   \n",
       "6       2023               SE              FT         Applied Scientist   \n",
       "7       2023               SE              FT            Data Scientist   \n",
       "8       2023               SE              FT            Data Scientist   \n",
       "9       2023               SE              FT            Data Scientist   \n",
       "\n",
       "   salary salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0   80000             EUR          85847                 ES           100   \n",
       "1   30000             USD          30000                 US           100   \n",
       "2   25500             USD          25500                 US           100   \n",
       "3  175000             USD         175000                 CA           100   \n",
       "4  120000             USD         120000                 CA           100   \n",
       "5  222200             USD         222200                 US             0   \n",
       "6  136000             USD         136000                 US             0   \n",
       "7  219000             USD         219000                 CA             0   \n",
       "8  141000             USD         141000                 CA             0   \n",
       "9  147100             USD         147100                 US             0   \n",
       "\n",
       "  company_location company_size  \n",
       "0               ES            L  \n",
       "1               US            S  \n",
       "2               US            S  \n",
       "3               CA            M  \n",
       "4               CA            M  \n",
       "5               US            L  \n",
       "6               US            L  \n",
       "7               CA            M  \n",
       "8               CA            M  \n",
       "9               US            M  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.   Mostrar información básica del dataframe con las columnas que lo componen, número valores no nulos, número valores nulos y tipo de datos de la columna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1682090742551,
     "user": {
      "displayName": "Carlos Sáenz Adán",
      "userId": "03415872180739491893"
     },
     "user_tz": -120
    },
    "id": "8jarH8sqm4FX",
    "outputId": "0015d377-5378-4f86-ffff-a0a8a7d79952"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de entradas:  3755\n",
      "Número de columnas:  11\n",
      "Número de nulos:  210\n",
      "Tipo de cada columna: \n",
      " work_year              int64\n",
      "experience_level      object\n",
      "employment_type       object\n",
      "job_title             object\n",
      "salary                 int64\n",
      "salary_currency       object\n",
      "salary_in_usd          int64\n",
      "employee_residence    object\n",
      "remote_ratio           int64\n",
      "company_location      object\n",
      "company_size          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def info(df):\n",
    "    print('Número de entradas: ', df.shape[0])\n",
    "    print('Número de columnas: ', df.shape[1])\n",
    "    print('Número de nulos: ', df.isnull().sum().sum())\n",
    "    print('Tipo de cada columna: \\n', df.dtypes)\n",
    "\n",
    "info(df_train)\n",
    "\n",
    "#df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.   Mostrar una lista con el nombre de columnas que son categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1682090742939,
     "user": {
      "displayName": "Carlos Sáenz Adán",
      "userId": "03415872180739491893"
     },
     "user_tz": -120
    },
    "id": "N3POWC5Zn04g",
    "outputId": "9b3806d0-aa77-4aaa-9605-3cba48c224fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['work_year', 'salary', 'salary_in_usd', 'remote_ratio']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnas_categoricas = df_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "columnas_categoricas\n",
    "\n",
    "## Para columnas numéricas\n",
    "columnas_numericas = df_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "columnas_numericas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.   Mostrar información básica de cada columna numérica (numero ocurrencias, media, desviación típica, valor mínimo, el valor máximo, y los límites de los cuartiles 25%, 50% y 75%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "executionInfo": {
     "elapsed": 407,
     "status": "ok",
     "timestamp": 1682090742938,
     "user": {
      "displayName": "Carlos Sáenz Adán",
      "userId": "03415872180739491893"
     },
     "user_tz": -120
    },
    "id": "dEjrGptVnvpN",
    "outputId": "22cb6e4f-11b6-49fb-8466-94661d9f03a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>remote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3755.000000</td>\n",
       "      <td>3.755000e+03</td>\n",
       "      <td>3755.000000</td>\n",
       "      <td>3755.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022.373635</td>\n",
       "      <td>1.906956e+05</td>\n",
       "      <td>137570.389880</td>\n",
       "      <td>46.271638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.691448</td>\n",
       "      <td>6.716765e+05</td>\n",
       "      <td>63055.625278</td>\n",
       "      <td>48.589050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>6.000000e+03</td>\n",
       "      <td>5132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>1.000000e+05</td>\n",
       "      <td>95000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022.000000</td>\n",
       "      <td>1.380000e+05</td>\n",
       "      <td>135000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023.000000</td>\n",
       "      <td>1.800000e+05</td>\n",
       "      <td>175000.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023.000000</td>\n",
       "      <td>3.040000e+07</td>\n",
       "      <td>450000.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         work_year        salary  salary_in_usd  remote_ratio\n",
       "count  3755.000000  3.755000e+03    3755.000000   3755.000000\n",
       "mean   2022.373635  1.906956e+05  137570.389880     46.271638\n",
       "std       0.691448  6.716765e+05   63055.625278     48.589050\n",
       "min    2020.000000  6.000000e+03    5132.000000      0.000000\n",
       "25%    2022.000000  1.000000e+05   95000.000000      0.000000\n",
       "50%    2022.000000  1.380000e+05  135000.000000      0.000000\n",
       "75%    2023.000000  1.800000e+05  175000.000000    100.000000\n",
       "max    2023.000000  3.040000e+07  450000.000000    100.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.   Mostrar información básica de cada columna categórica (número de ocurrencias no nulas, número de valores únicos, valor que más se repite y cuántas veces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          7\n",
       "unique         1\n",
       "top       object\n",
       "freq           7\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes[df_train.dtypes == 'object'].describe()\n",
    "\n",
    "#df_train.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wq_EHVsiEUN"
   },
   "source": [
    "## Ejercicio 3. Unificar las ocurrencias de empresas tamaño L, M y S (2.5 puntos)\n",
    "\n",
    "Crea un dataframe en el que iguales las ocurrencias cuyo tamaño de empresa es L, M y S de tal forma que haya 500 de cada una. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1682090742940,
     "user": {
      "displayName": "Carlos Sáenz Adán",
      "userId": "03415872180739491893"
     },
     "user_tz": -120
    },
    "id": "euaaBcgHwAfN",
    "outputId": "0624e3f3-8237-4486-ff54-4769a44b00fc"
   },
   "outputs": [],
   "source": [
    "# Split data into two dataframes because data is not balanced\n",
    "df_S = df_train[df_train['company_size']=='S']\n",
    "df_M = df_train[df_train['company_size']=='M']\n",
    "df_L = df_train[df_train['company_size']=='L']\n",
    "\n",
    "# Para igualar los datos de los df, tanto para cortar como para añadir datos.\n",
    "df_downsampledS = resample(df_S,\n",
    "                                 n_samples=500,\n",
    "                                 replace=True,      # sample with replacement\n",
    "                                 random_state=42)   # reproducible results\n",
    "df_downsampledM = resample(df_M,\n",
    "                                 n_samples=500,\n",
    "                                 replace=True,      # sample with replacement\n",
    "                                 random_state=42)   # reproducible results\n",
    "df_downsampledL = resample(df_L,\n",
    "                                 n_samples=500,\n",
    "                                 replace=True,      # sample with replacement\n",
    "                                 random_state=42)   # reproducible results\n",
    "\n",
    "df = pd.concat([df_downsampledS, df_downsampledM, df_downsampledL])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar que efectivamente hay 500 de cada valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de occurrencias clase S: 500\n",
      "Numero de occurrencias clase M: 500\n",
      "Numero de occurrencias clase L: 500\n"
     ]
    }
   ],
   "source": [
    "print(f\"Numero de occurrencias clase S: {len(df[df.company_size=='S'])}\")\n",
    "print(f\"Numero de occurrencias clase M: {len(df[df.company_size=='M'])}\")\n",
    "print(f\"Numero de occurrencias clase L: {len(df[df.company_size=='L'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAY2B2kwmS5_"
   },
   "source": [
    "# Ejercicio 4. Modificar dataset (1 punto)\n",
    "\n",
    "La columna employee_residence indica el pais de residencia del empleado. **Crea una función** que reciba como parámetro un dataframe y elimine aquellos empleados que pertenecen a paises con menos de 10 empleados en el dataset. \n",
    "\n",
    "**El número de ocurrencias se queda en 1337.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas después de la filtración: 3581\n"
     ]
    }
   ],
   "source": [
    "#copia_df_train = df_train.copy\n",
    "\n",
    "#def modficarColumna(df):\n",
    "#    X = X.drop()\n",
    "    \n",
    "#modficarColumna(copia_df_train)\n",
    "\n",
    "### GPT\n",
    "\n",
    "def remove_low_frequency_countries(df, min_employees=10):\n",
    "    # Contar el número de empleados por país\n",
    "    country_counts = df['employee_residence'].value_counts()\n",
    "    \n",
    "    # Identificar países con al menos 10 empleados\n",
    "    countries_to_keep = country_counts[country_counts >= min_employees].index\n",
    "    \n",
    "    # Filtrar el dataframe para mantener solo los países con suficientes empleados\n",
    "    df_filtered = df[df['employee_residence'].isin(countries_to_keep)]\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# Aplicar la función al dataframe original df_train\n",
    "df_filtered = remove_low_frequency_countries(df_train)\n",
    "\n",
    "# Verificar el número de filas resultantes\n",
    "print(f\"Número de filas después de la filtración: {len(df_filtered)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZiIpSodbruZ"
   },
   "source": [
    "# Ejercicio 5. Eliminar nulos (0.5 punto)\n",
    "\n",
    "Crea un transformador (llamado 'EliminarColumnasNulas') que identifique en el dataset las columnas que tienen más de un 9% de nulos y las elimine. **NO LO APLIQUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1682090744131,
     "user": {
      "displayName": "Carlos Sáenz Adán",
      "userId": "03415872180739491893"
     },
     "user_tz": -120
    },
    "id": "3-jl2lwlbys8",
    "outputId": "399b459a-fea1-49a8-b83a-4f430577fc3e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m copia_df_train \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEliminarColumnasNulas\u001b[39;00m(df,\u001b[43mperc\u001b[49m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      5\u001b[0m         cols_with_missing \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'perc' is not defined"
     ]
    }
   ],
   "source": [
    "copia_df_train = df_train.copy\n",
    "\n",
    "class EliminarColumnasNulas(df,perc):\n",
    "    def fit(self, X, y=None):\n",
    "        cols_with_missing = df.isnull().sum()\n",
    "        self.col_with_perc = cols_with_missing[cols_with_missing > 0]/len(df)*100\n",
    "        return self.col_with_perc[col_with_perc>perc]\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.values\n",
    "    \n",
    "#### GPT\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EliminarColumnasNulas(BaseEstimator, TransformerMixin):\n",
    "    threshold = 0.09\n",
    "    columns_to_drop = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calcular el porcentaje de valores nulos en cada columna\n",
    "        null_percentages = X.isnull().mean()\n",
    "        \n",
    "        # Identificar las columnas con más del threshold% de valores nulos\n",
    "        self.columns_to_drop = null_percentages[null_percentages > self.threshold].index.tolist()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Crear una copia del dataframe\n",
    "        X_transformed = X.copy()\n",
    "        \n",
    "        # Eliminar las columnas identificadas\n",
    "        if self.columns_to_drop:\n",
    "            X_transformed = X_transformed.drop(columns=self.columns_to_drop)\n",
    "        \n",
    "        return X_transformed\n",
    "\n",
    "# Crear una instancia del transformador (NO LO APLICAMOS)\n",
    "eliminar_nulos = EliminarColumnasNulas()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7-dOoWAiwCu"
   },
   "source": [
    "# Ejercicio 6. Transformar variables categóricas a numéricas (2.5 puntos)\n",
    "\n",
    "Crea un transformador (llamado CompanyTransformer) que transforme la columna categórica 'company_size' en numérica. Para ello debes crear tu propio mapeo teniendo en cuenta la magnitud de los valores que asignes. **(0.5 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompanyTransformer(df):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.values\n",
    "    \n",
    "\n",
    "## GPT\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CompanyTransformer(BaseEstimator, TransformerMixin):\n",
    "    company_size_map = {'S': 10, 'M': 50, 'L': 250}\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed['company_size'] = X_transformed['company_size'].map(self.company_size_map)\n",
    "        return X_transformed\n",
    "\n",
    "# Crear una instancia del transformador (NO LO APLICAMOS)\n",
    "company_transformer = CompanyTransformer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un transformador (llamado 'CustomLabelEncoder') que aplique LabelEncoder a una columna concreta que se pase por parámetro. Impleméntalo de tal forma que te asegures que dicha columna existe y además que sea categórica. **(1 punto)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLabelEncoder(BaseEstimator, TransformerMixin, df,columna):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "    def fit(self, X, y=None):\n",
    "        # Primero, identificamos las columnas categóricas\n",
    "        columnas_categoricas = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        # Creamos label encoder\n",
    "        #self.label_encoder = LabelEncoder()\n",
    "        #df = pd.get_dummies(df, columns=[col for col in columnas_categoricas if col != columna])\n",
    "        #self.label_encoder.fit(df)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        for col in self.columns:\n",
    "            X = pd.concat([X,pd.get_dummies(X[col], prefix=col)], axis=1)\n",
    "            X = X.drop(col,axis=1)\n",
    "        return X\n",
    "    \n",
    "## GPT\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "class CustomLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "        self.label_encoder = LabelEncoder()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # Verificar si la columna existe\n",
    "        if self.column not in X.columns:\n",
    "            raise ValueError(f\"La columna '{self.column}' no existe en el DataFrame\")\n",
    "        \n",
    "        # Verificar si la columna es categórica\n",
    "        if not pd.api.types.is_categorical_dtype(X[self.column]): # if X[self.column_name].dtype not in ['object', 'category']:\n",
    "            raise ValueError(f\"La columna '{self.column}' no es categórica\")\n",
    "        \n",
    "        # Ajustar el LabelEncoder\n",
    "        self.label_encoder.fit(X[self.column])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        X_transformed[self.column] = self.label_encoder.transform(X[self.column])\n",
    "        return X_transformed\n",
    "    \n",
    "# Ejemplo de uso\n",
    "# Suponiendo que df_train es tu DataFrame\n",
    "# transformador = CustomLabelEncoder('job_title')\n",
    "# df_train_transformado = transformador.fit_transform(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un transformador (llamado 'MiNormalizador') que normalice cada una de las columnas pertenecientes a una lista que se pasen por parámetro en el constructor. No se puede utilizar ninguna clase para normalizar. **(1 punto)**\n",
    "\n",
    "Recuerdo la formula de la normalización:\n",
    "\n",
    "$x^i_{norm} = \\frac{x^i-x_{min}}{x_{max}-x_{min}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiNormalizador(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.minimo = X.min()\n",
    "        self.maximo = X.max()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = (X - self.minimo) / (self.maximo - self.minimo)\n",
    "        return X.values\n",
    "    \n",
    "\n",
    "## GPT\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "\n",
    "class MiNormalizador(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columnas):\n",
    "        # Recibimos una lista de columnas a normalizar\n",
    "        self.columnas = columnas\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Verificamos que todas las columnas existan en el DataFrame\n",
    "        for columna in self.columnas:\n",
    "            if columna not in X.columns:\n",
    "                raise ValueError(f\"La columna '{columna}' no existe en el DataFrame.\")\n",
    "        \n",
    "        # Guardamos los valores mínimos y máximos de cada columna\n",
    "        self.minimos = X[self.columnas].min()\n",
    "        self.maximos = X[self.columnas].max()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Creamos una copia del DataFrame para no modificar el original\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        # Normalizamos cada columna usando la fórmula de normalización\n",
    "        for columna in self.columnas:\n",
    "            X_copy[columna] = (X_copy[columna] - self.minimos[columna]) / (self.maximos[columna] - self.minimos[columna])\n",
    "\n",
    "        return X_copy\n",
    "\n",
    "# Ejemplo de uso\n",
    "# transformador = MiNormalizador(['salary', 'salary_in_usd'])\n",
    "# df_train_normalizado = transformador.fit_transform(df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYMizPNaieJa"
   },
   "source": [
    "# Ejercicio 7. Construcción pipelines (2 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el objetivo de ayudarte, te ofrezco la estructura de un transformador llamado Info(). Este transformador lo puedes utilizar para mostrar información o datos del dataset en un momento determinado del pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Info(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        #insertar código para mostrar información que quieras del dataset\n",
    "        print(X.info())\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construye un pipeline que permita ejecutar el conjunto de transformadores que he definido anteriormente. **(1 punto)**\n",
    "1. EliminarColumnasNulas\n",
    "2. CompanyTransformer\n",
    "3. CustomLabelEncoder aplicándolo a experience_level y company_location\n",
    "4. Finalmente normaliza las columnas numéricas utilizando MiNormalizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('EliminarColumnasNulas', EliminarColumnasNulas(df_train,9)),\n",
    "    ('CompanyTransformer', CompanyTransformer()),\n",
    "    ('CustomLabelEncoder', CustomLabelEncoder()),\n",
    "    ('normalizar', MiNormalizador())\n",
    "])\n",
    "\n",
    "pipeline.fit_transform(df)\n",
    "\n",
    "\n",
    "## GPT\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Definimos las columnas numéricas que queremos normalizar\n",
    "columnas_numericas = ['work_year', 'salary', 'salary_in_usd', 'remote_ratio']\n",
    "\n",
    "# Construimos el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('eliminar_nulos', EliminarColumnasNulas()),\n",
    "    ('info_1', Info()),  # Mostramos información después de eliminar columnas nulas\n",
    "    ('company_transformer', CompanyTransformer()),\n",
    "    ('info_2', Info()),  # Mostramos información después de transformar company_size\n",
    "    ('label_encoder_experience', CustomLabelEncoder(column='experience_level')),\n",
    "    ('label_encoder_location', CustomLabelEncoder(column='company_location')),\n",
    "    ('info_3', Info()),  # Mostramos información después de aplicar label encoding\n",
    "    ('normalizador', MiNormalizador(columns=columnas_numericas)),\n",
    "    ('info_final', Info())  # Mostramos información final\n",
    "])\n",
    "\n",
    "# Aplicamos el pipeline al dataset\n",
    "df_transformado = pipeline.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide el dataset en dos conjuntos, uno de entrenamiento con el 95% de los datos y otro de test con el 5%. La columna a predecir será \"salary\". **(0.5 puntos)**\n",
    "\n",
    "Como resultado deberás obtener:\n",
    "1. un subconjunto del dataset que represente el 95% de los datos SIN la columna salary. (X_train)\n",
    "2. los valores de la columna salary del anterior subconjunto. (y_train)\n",
    "3. un subconjunto del dataset que represente el 5% de los datos SIN la columna salary. (X_test)\n",
    "4. los valores de la columna salary del anterior subconjunto. (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "\n",
    "## GPT\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separamos las características (X) y la variable objetivo (y)\n",
    "X = df_transformado.drop('salary', axis=1)\n",
    "y = df_transformado['salary']\n",
    "\n",
    "# Dividimos los datos en conjuntos de entrenamiento (95%) y prueba (5%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "\n",
    "# Verificamos los tamaños de los conjuntos\n",
    "print(\"Tamaño de X_train:\", X_train.shape)\n",
    "print(\"Tamaño de y_train:\", y_train.shape)\n",
    "print(\"Tamaño de X_test:\", X_test.shape)\n",
    "print(\"Tamaño de y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba la ejecución del pipeline con el conjunto de entrenamiento y con el de test. **(0.5 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejecucion = pipeline()\n",
    "\n",
    "ejecucion.fit_transform(X_train)\n",
    "\n",
    "\n",
    "## GPT\n",
    "\n",
    "# Aplicamos el pipeline al conjunto de entrenamiento\n",
    "X_train_transformed = pipeline.fit_transform(X_train)\n",
    "\n",
    "# Aplicamos el pipeline al conjunto de test\n",
    "X_test_transformed = pipeline.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM3X7dlkDCVKbTSgiPmCdwt",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
