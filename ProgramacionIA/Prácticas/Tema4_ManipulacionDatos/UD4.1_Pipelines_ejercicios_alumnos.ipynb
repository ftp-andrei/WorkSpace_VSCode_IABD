{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicios sobre pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos Iris\n",
    "iris = load_iris(as_frame=True).frame\n",
    "X = iris.drop(columns='target', axis=1)\n",
    "y = iris['target']\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Crea un pipeline que tenga como tarea normalizar, para ello, utiliza la clase MinMaxScaler. Comprueba el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir datos categóricos a numéricos si es necesario\n",
    "X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# Asegurarte de que ambas particiones tengan las mismas columnas\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# NO HACE FALTA PERO POR SI ACASO DA FALLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Crear el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),       # Normalización\n",
    "    ('pca', PCA(n_components=2)),    # Reducción de dimensionalidad\n",
    "    ('svc', SVC(kernel='linear'))    # Clasificación con SVM\n",
    "])\n",
    "\n",
    "# Entrenar el pipeline con el conjunto de entrenamiento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predecir los valores para el conjunto de prueba\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calcular y mostrar la precisión\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un pipeline que tenga como tarea estandarizar, para ello, utiliza la clase StandardScaler. Comprueba el resultado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Crear el pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),    # Estandarización\n",
    "    ('pca', PCA(n_components=2)),    # Reducción de dimensionalidad\n",
    "    ('svc', SVC(kernel='linear'))    # Clasificación con SVM\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo con estandarización: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el pipeline con el conjunto de entrenamiento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predecir los valores para el conjunto de prueba\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calcular y mostrar la precisión\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo con estandarización: {accuracy:.2f}\")\n",
    "\n",
    "# jaime\n",
    "# pipeline2.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Crea tu propio transformador que normalize un conjunto. Recuerda que la fórmula para normalizar es la siguiente:\n",
    "\n",
    "```\n",
    "xi_normalizada = xi - min(x) / max(ex) - min(ex)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "* *xi* es el valor a normalizar.\n",
    "* *min(x)* es el mínimo del conjunto de los datos.\n",
    "* *min(x)* es el máximo del conjunto de los datos.\n",
    "* *xi_normalizada* es el valor de xi normalizado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class CustomNormalizer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # Calcular los valores mínimos y máximos para cada característica\n",
    "        self.min_ = X.min(axis=0)\n",
    "        self.max_ = X.max(axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X - self.min_) / (self.max_ - self.min_)\n",
    "\n",
    "    def inverse_transform(self, X):\n",
    "        # Revertir la normalización\n",
    "        return X * (self.max_ - self.min_) + self.min_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba que el resultado es igual que el que el de la clase MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Datos de ejemplo\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature1\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m50\u001b[39m],\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature2\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m500\u001b[39m]\n\u001b[0;32m      8\u001b[0m }\n\u001b[1;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Usar el transformador personalizado\u001b[39;00m\n\u001b[0;32m     12\u001b[0m custom_normalizer \u001b[38;5;241m=\u001b[39m CustomNormalizer()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# jaime\n",
    "pipeline3 = Pipeline([\n",
    "    ('normalizacion', CustomNormalizer())\n",
    "])\n",
    "\n",
    "pipeline3.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Crea tu propio transformador que estandarice un conjunto. Recuerda que la fórmula para estandarizar es la siguiente:\n",
    "\n",
    "```\n",
    "xi_estandarizada = (xi - media(x)) / std(x)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "* *xi* es el valor a estandarizar.\n",
    "* *media(x)* es la media de los datos.\n",
    "* *std(x)* es la desviación típica de los datos.\n",
    "* *xi_estandarizada* es el valor de xi estandarizado.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# Definir el transformador personalizado para estandarizar\n",
    "class MiEstandarizador(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.media = X.mean()  # Calcula la media de cada columna\n",
    "        self.std = X.std()     # Calcula la desviación estándar de cada columna\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Establecer la fórmula para estandarizar cada valor\n",
    "        X_estandarizado = (X - self.media) / self.std\n",
    "        return X_estandarizado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MiEstandarizador' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Crear un pipeline que incluya el estandarizador y un clasificador SVM\u001b[39;00m\n\u001b[0;32m      6\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m----> 7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestandarizador\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mMiEstandarizador\u001b[49m()),  \u001b[38;5;66;03m# Usamos nuestro transformador personalizado\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvm\u001b[39m\u001b[38;5;124m'\u001b[39m, SVC())                          \u001b[38;5;66;03m# Modelo de clasificación\u001b[39;00m\n\u001b[0;32m      9\u001b[0m ])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Ajustar el pipeline con los datos de entrenamiento\u001b[39;00m\n\u001b[0;32m     12\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MiEstandarizador' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Crear un pipeline que incluya el estandarizador y un clasificador SVM\n",
    "pipeline = Pipeline([\n",
    "    ('estandarizador', MiEstandarizador()),  # Usamos nuestro transformador personalizado\n",
    "    ('svm', SVC())                          # Modelo de clasificación\n",
    "])\n",
    "\n",
    "# Ajustar el pipeline con los datos de entrenamiento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predecir con el conjunto de prueba\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# jaime\n",
    "# pipeline4 = Pipeline([\n",
    "#     ('estandarizacion2', TransformadorCrisis2())\n",
    "# ])\n",
    "\n",
    "# pipeline4.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprueba que el resultado es igual que el de StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Los resultados son iguales? False\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Aplicamos StandardScaler a X_train\n",
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train)\n",
    "\n",
    "# Usamos nuestro transformador personalizado MiEstandarizador\n",
    "mi_estandarizador = MiEstandarizador()\n",
    "X_train_mi_estandarizado = mi_estandarizador.fit_transform(X_train)\n",
    "\n",
    "# Comprobamos si los resultados son iguales (deberían serlo si todo funciona correctamente)\n",
    "# Podemos usar np.allclose para comparar los resultados (debido a pequeñas diferencias numéricas)\n",
    "resultados_iguales = np.allclose(X_train_standardized, X_train_mi_estandarizado)\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f\"¿Los resultados son iguales? {resultados_iguales}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4. \n",
    "\n",
    "Crea tu propio transformador, aplicará el mismo LabelEncoder a todas las columnas categóricas del siguiente dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos Iris\n",
    "iris = load_iris(as_frame=True).frame\n",
    "X = iris.drop(columns='target', axis=1)\n",
    "y = iris['target']\n",
    "\n",
    "# Calculo la mitad del dataset\n",
    "midpoint = len(X) // 2\n",
    "\n",
    "# Asigno valores diferentes a la mitad de la columna\n",
    "X.loc[:midpoint, 'categorica1'] = 'valor1'\n",
    "X.loc[midpoint:, 'categorica1'] = 'valor2'\n",
    "\n",
    "# Asigno valores diferentes a la mitad de la columna\n",
    "X.loc[:midpoint, 'categorica2'] = 'valor2'\n",
    "X.loc[midpoint:, 'categorica2'] = 'valor1'\n",
    "\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "22                 4.6               3.6                1.0               0.2   \n",
      "15                 5.7               4.4                1.5               0.4   \n",
      "65                 6.7               3.1                4.4               1.4   \n",
      "11                 4.8               3.4                1.6               0.2   \n",
      "42                 4.4               3.2                1.3               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "71                 6.1               2.8                4.0               1.3   \n",
      "106                4.9               2.5                4.5               1.7   \n",
      "14                 5.8               4.0                1.2               0.2   \n",
      "92                 5.8               2.6                4.0               1.2   \n",
      "102                7.1               3.0                5.9               2.1   \n",
      "\n",
      "    categorica1 categorica2  \n",
      "22       valor1      valor2  \n",
      "15       valor1      valor2  \n",
      "65       valor1      valor2  \n",
      "11       valor1      valor2  \n",
      "42       valor1      valor2  \n",
      "..          ...         ...  \n",
      "71       valor1      valor2  \n",
      "106      valor2      valor1  \n",
      "14       valor1      valor2  \n",
      "92       valor2      valor1  \n",
      "102      valor2      valor1  \n",
      "\n",
      "[120 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# Imprime los datos de entrenamiento para ver el conjunto X_train\n",
    "print(X_train)\n",
    "\n",
    "# Definir un transformador personalizado heredando de BaseEstimator y TransformerMixin\n",
    "class MiLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # Método fit para ajustar el transformador a los datos\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        # Seleccionar solo las columnas categóricas (de tipo object)\n",
    "        self.columnas_categoricas = list(X.dtypes[X.dtypes == object].index)\n",
    "\n",
    "        # Inicializar una lista para almacenar los valores únicos de todas las columnas categóricas\n",
    "        valores_unicos = list()\n",
    "        for c in self.columnas_categoricas:\n",
    "            # Obtener los valores únicos de cada columna y agregarlo a la lista\n",
    "            valores_unicos.extend(X[c].unique())\n",
    "\n",
    "        # Eliminar valores duplicados\n",
    "        valores_unicos = np.unique(valores_unicos)\n",
    "\n",
    "        # Crear un LabelEncoder y ajustarlo con los valores únicos de las columnas categóricas\n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(valores_unicos)  # Ajustar el encoder a todos los valores posibles\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Método transform para aplicar el ajuste a los datos\n",
    "    def transform(self, X, y=None):\n",
    "        # Iterar sobre cada columna categórica y transformarla\n",
    "        for c in self.columnas_categoricas:\n",
    "            # Usar el LabelEncoder ajustado para transformar los valores\n",
    "            X[c] = self.le.transform(X[c])\n",
    "        return X    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>categorica1</th>\n",
       "      <th>categorica2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "22                 4.6               3.6                1.0               0.2   \n",
       "15                 5.7               4.4                1.5               0.4   \n",
       "65                 6.7               3.1                4.4               1.4   \n",
       "11                 4.8               3.4                1.6               0.2   \n",
       "42                 4.4               3.2                1.3               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "71                 6.1               2.8                4.0               1.3   \n",
       "106                4.9               2.5                4.5               1.7   \n",
       "14                 5.8               4.0                1.2               0.2   \n",
       "92                 5.8               2.6                4.0               1.2   \n",
       "102                7.1               3.0                5.9               2.1   \n",
       "\n",
       "     categorica1  categorica2  \n",
       "22             0            1  \n",
       "15             0            1  \n",
       "65             0            1  \n",
       "11             0            1  \n",
       "42             0            1  \n",
       "..           ...          ...  \n",
       "71             0            1  \n",
       "106            1            0  \n",
       "14             0            1  \n",
       "92             1            0  \n",
       "102            1            0  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciar el transformador personalizado\n",
    "mlbe = MiLabelEncoder()\n",
    "\n",
    "# Ajustar y transformar el conjunto de entrenamiento X_train\n",
    "mlbe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "22                 4.6               3.6                1.0               0.2   \n",
      "15                 5.7               4.4                1.5               0.4   \n",
      "65                 6.7               3.1                4.4               1.4   \n",
      "11                 4.8               3.4                1.6               0.2   \n",
      "42                 4.4               3.2                1.3               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "71                 6.1               2.8                4.0               1.3   \n",
      "106                4.9               2.5                4.5               1.7   \n",
      "14                 5.8               4.0                1.2               0.2   \n",
      "92                 5.8               2.6                4.0               1.2   \n",
      "102                7.1               3.0                5.9               2.1   \n",
      "\n",
      "     categorica1  categorica2  \n",
      "22             0            1  \n",
      "15             0            1  \n",
      "65             0            1  \n",
      "11             0            1  \n",
      "42             0            1  \n",
      "..           ...          ...  \n",
      "71             0            1  \n",
      "106            1            0  \n",
      "14             0            1  \n",
      "92             1            0  \n",
      "102            1            0  \n",
      "\n",
      "[120 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# OTRO EJEMPLO SIN LABELENCODER\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# Imprime los datos de entrenamiento para ver el conjunto X_train\n",
    "print(X_train)\n",
    "\n",
    "# Definir un transformador personalizado heredando de BaseEstimator y TransformerMixin\n",
    "class MiLabelEncoder2(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # Método fit para ajustar el transformador a los datos\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        # Seleccionar solo las columnas categóricas (de tipo object)\n",
    "        self.columnas_categoricas = list(X.dtypes[X.dtypes == object].index)\n",
    "\n",
    "        # Inicializar una lista para almacenar los valores únicos de todas las columnas categóricas\n",
    "        valores_unicos = list()\n",
    "        for c in self.columnas_categoricas:\n",
    "            # Obtener los valores únicos de cada columna y agregarlo a la lista\n",
    "            valores_unicos.extend(X[c].unique())\n",
    "\n",
    "        # Eliminar valores duplicados\n",
    "        valores_unicos = np.unique(valores_unicos)\n",
    "        \n",
    "        # Mapeo sin LabelEncoder\n",
    "        self.mapeo={}\n",
    "        i=0\n",
    "        for v in valores_unicos:\n",
    "            self.mapeo[v]=i\n",
    "            i=i+1\n",
    "        return self\n",
    "\n",
    "    # Método transform para aplicar el ajuste a los datos\n",
    "    def transform(self, X, y=None):\n",
    "        # Iterar sobre cada columna categórica y transformarla\n",
    "        for c in self.columnas_categoricas:\n",
    "            # Usamos el map\n",
    "            X[c] = X[c].map(self.mapeo)\n",
    "        return X    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "22                 4.6               3.6                1.0               0.2   \n",
      "15                 5.7               4.4                1.5               0.4   \n",
      "65                 6.7               3.1                4.4               1.4   \n",
      "11                 4.8               3.4                1.6               0.2   \n",
      "42                 4.4               3.2                1.3               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "71                 6.1               2.8                4.0               1.3   \n",
      "106                4.9               2.5                4.5               1.7   \n",
      "14                 5.8               4.0                1.2               0.2   \n",
      "92                 5.8               2.6                4.0               1.2   \n",
      "102                7.1               3.0                5.9               2.1   \n",
      "\n",
      "     categorica1  categorica2  \n",
      "22             0            1  \n",
      "15             0            1  \n",
      "65             0            1  \n",
      "11             0            1  \n",
      "42             0            1  \n",
      "..           ...          ...  \n",
      "71             0            1  \n",
      "106            1            0  \n",
      "14             0            1  \n",
      "92             1            0  \n",
      "102            1            0  \n",
      "\n",
      "[120 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# UTILIZO UN LABEL ENCODER DIFERENTE PARA CADA COLUMNA CATEGORICA\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# Imprime los datos de entrenamiento para ver el conjunto X_train\n",
    "print(X_train)\n",
    "\n",
    "# Definir un transformador personalizado heredando de BaseEstimator y TransformerMixin\n",
    "class MiLabelEncoder3(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # Método fit para ajustar el transformador a los datos\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        # Seleccionar solo las columnas categóricas (de tipo object)\n",
    "        columnas_categoricas = list(X.dtypes[X.dtypes == object].index)\n",
    "\n",
    "        self.label_encoders = {}\n",
    "        for c in columnas_categoricas:\n",
    "            self.label_encoders[c] = LabelEncoder()\n",
    "            self.label_encoders[c].fit(X[c])\n",
    "\n",
    "        return self\n",
    "\n",
    "    # Método transform para aplicar el ajuste a los datos\n",
    "    def transform(self, X, y=None):\n",
    "        # Iterar sobre cada columna categórica y transformarla\n",
    "        for c in self.columnas_categoricas:\n",
    "            # Usar el LabelEncoder ajustado para transformar los valores\n",
    "            X[c] = self.le.transform(X[c])\n",
    "        return X    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "\n",
    "Crea tu propio transformador para aplicar la técnica de one_hot_encoding a un conjunto de columnas que pasaré como parámetro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "22                 4.6               3.6                1.0               0.2   \n",
      "15                 5.7               4.4                1.5               0.4   \n",
      "65                 6.7               3.1                4.4               1.4   \n",
      "11                 4.8               3.4                1.6               0.2   \n",
      "42                 4.4               3.2                1.3               0.2   \n",
      "..                 ...               ...                ...               ...   \n",
      "71                 6.1               2.8                4.0               1.3   \n",
      "106                4.9               2.5                4.5               1.7   \n",
      "14                 5.8               4.0                1.2               0.2   \n",
      "92                 5.8               2.6                4.0               1.2   \n",
      "102                7.1               3.0                5.9               2.1   \n",
      "\n",
      "     categorica1  categorica2  \n",
      "22             0            1  \n",
      "15             0            1  \n",
      "65             0            1  \n",
      "11             0            1  \n",
      "42             0            1  \n",
      "..           ...          ...  \n",
      "71             0            1  \n",
      "106            1            0  \n",
      "14             0            1  \n",
      "92             1            0  \n",
      "102            1            0  \n",
      "\n",
      "[120 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "# Imprime los datos de entrenamiento para ver el conjunto X_train\n",
    "print(X_train)\n",
    "\n",
    "# Definir un transformador personalizado heredando de BaseEstimator y TransformerMixin\n",
    "class MiOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "    # Método fit para ajustar el transformador a los datos\n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        return self\n",
    "\n",
    "    # Método transform para aplicar el ajuste a los datos\n",
    "    def transform(self, X):\n",
    "        for col in self.columns:\n",
    "            X = pd.concat([X,pd.get_dummies(X[col], prefix=col)], axis=1)\n",
    "            X = X.drop(col,axis=1)\n",
    "        return X    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>categorica2</th>\n",
       "      <th>categorica1_0</th>\n",
       "      <th>categorica1_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>7.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "22                 4.6               3.6                1.0               0.2   \n",
       "15                 5.7               4.4                1.5               0.4   \n",
       "65                 6.7               3.1                4.4               1.4   \n",
       "11                 4.8               3.4                1.6               0.2   \n",
       "42                 4.4               3.2                1.3               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "71                 6.1               2.8                4.0               1.3   \n",
       "106                4.9               2.5                4.5               1.7   \n",
       "14                 5.8               4.0                1.2               0.2   \n",
       "92                 5.8               2.6                4.0               1.2   \n",
       "102                7.1               3.0                5.9               2.1   \n",
       "\n",
       "     categorica2  categorica1_0  categorica1_1  \n",
       "22             1           True          False  \n",
       "15             1           True          False  \n",
       "65             1           True          False  \n",
       "11             1           True          False  \n",
       "42             1           True          False  \n",
       "..           ...            ...            ...  \n",
       "71             1           True          False  \n",
       "106            0          False           True  \n",
       "14             1           True          False  \n",
       "92             0          False           True  \n",
       "102            0          False           True  \n",
       "\n",
       "[120 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instanciar el transformador personalizado\n",
    "mlbe = MiOneHotEncoder(columns=['categorica1'])\n",
    "\n",
    "# Ajustar y transformar el conjunto de entrenamiento X_train\n",
    "mlbe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplica el transformador a las columnas categóricas del siguiente dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos Iris\n",
    "iris = load_iris(as_frame=True).frame\n",
    "X = iris.drop(columns='target', axis=1)\n",
    "y = iris['target']\n",
    "\n",
    "# Calculo la mitad del dataset\n",
    "midpoint = len(X) // 2\n",
    "\n",
    "# Asigno valores diferentes a la mitad de la columna\n",
    "X.loc[:midpoint, 'categorica1'] = 'valor1'\n",
    "X.loc[midpoint:, 'categorica1'] = 'valor2'\n",
    "\n",
    "# Asigno valores diferentes a la mitad de la columna\n",
    "X.loc[:midpoint, 'categorica2'] = 'valor2'\n",
    "X.loc[midpoint:, 'categorica2'] = 'valor1'\n",
    "\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 6\n",
    "\n",
    "Crea un transformador llamado MultiplierTransformer que tome un conjunto de datos y multiplique todas las características numéricas por un factor específico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformador5(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, valor):\n",
    "      self.valor = valor\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "      return self\n",
    "\n",
    "    def transform(self, X):\n",
    "      X = X * self.valor\n",
    "      return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe un ejemplo de uso utilizando el siguiente dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de uso con un DataFrame de pandas\n",
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline7 = Pipeline([\n",
    "    ('TransformadorAntiVacio', Transformador5())\n",
    "])\n",
    "\n",
    "pipeline7.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 7\n",
    "\n",
    "Desarrolla un transformador llamado MissingDataImputerNumerical que sustituya los datos faltantes en las columnas por el valor de la media de cada columna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([int64, int64, int64], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m columnas_numericas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mdtypes[df\u001b[38;5;241m.\u001b[39mdtypes[df\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mindex])\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumnas_numericas\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([int64, int64, int64], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "columnas_numericas=list(df.dtypes[df.dtypes[df.dtypes!='object'].index])\n",
    "\n",
    "df[columnas_numericas].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MissingDataImputerNumerical(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        columnas_numericas=list(X.dtypes[X.dtypes[X.dtypes!='object'].index])\n",
    "        self.medias= X[columnas_numericas].mean()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.medias)\n",
    "    \n",
    "    # otra forma\n",
    "    # X.replace(np.nan, self.medias)\n",
    "\n",
    "    # Otra forma es en el fit solo poner \n",
    "    # self.medias = X.meal()\n",
    "    # return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta un ejemplo utilizando el siguiente dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'A': [1, 2, np.nan], 'B': [4, np.nan, 6], 'C': [7, 8, 9]}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([float64, float64, int64], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m mdin \u001b[38;5;241m=\u001b[39m MissingDataImputerNumerical()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmdin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "Cell \u001b[1;32mIn[29], line 6\u001b[0m, in \u001b[0;36mMissingDataImputerNumerical.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      5\u001b[0m     columnas_numericas\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(X\u001b[38;5;241m.\u001b[39mdtypes[X\u001b[38;5;241m.\u001b[39mdtypes[X\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mindex])\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmedias\u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumnas_numericas\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([float64, float64, int64], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "mdin = MissingDataImputerNumerical()\n",
    "mdin.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 8\n",
    "\n",
    "Desarrolla un transformador llamado MissingDataImputerCategorical que sustituya los datos faltantes en las columnas categóricas por el valor que más veces aparezca. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacamos el valor que mas se repite\n",
    "    \n",
    "df['D'].value_counts().sort_values(ascending=False).index[0]\n",
    "# Otra forma\n",
    "# df['D'].value_counts().idxmax()\n",
    "# Otra forma\n",
    "# df['D'].mode()\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class MissingDataImputerCategorical(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.modas= {}\n",
    "        for c in X.columns:\n",
    "            self.modas[c]= X[c].mode().iloc[0]\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X.fillna(self.modas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecuta un ejemplo utilizando el siguiente dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>a</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>b</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B   C    D    E\n",
       "0  1.0  4.0   7    a    x\n",
       "1  2.0  NaN   8    a    c\n",
       "2  NaN  6.0   9  NaN  NaN\n",
       "3  4.0  5.0  10    b    x"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, np.nan, 4], 'B': [4, np.nan, 6, 5], 'C': [7, 8, 9, 10], 'D': ['a', 'a', np.nan,'b'], 'E': ['x', 'c', np.nan,'x']}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MissingDataImputerCategorical' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mdic\u001b[38;5;241m=\u001b[39m \u001b[43mMissingDataImputerCategorical\u001b[49m()\n\u001b[0;32m      2\u001b[0m mdic\u001b[38;5;241m.\u001b[39mfit_transform(df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MissingDataImputerCategorical' is not defined"
     ]
    }
   ],
   "source": [
    "mdic= MissingDataImputerCategorical()\n",
    "mdic.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2025738096.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    fit:\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# CUANDO USAR FIT Y CUANDO TRANSFORM\n",
    "\n",
    "#fit:\n",
    "\n",
    "    #Se usa solo con X_train.\n",
    "    #Su propósito es aprender los parámetros del transformador (como la media y desviación estándar para la normalización o los rangos para escalado).\n",
    "    #No debe usarse con X_test, ya que X_test debe mantenerse independiente y solo transformarse usando los parámetros aprendidos de X_train.\n",
    "\n",
    "#transform:\n",
    "\n",
    "    #Se usa con X_train y X_test después de usar fit con X_train.\n",
    "    #Aplica la transformación basada en los parámetros aprendidos durante el fit en X_train.\n",
    "    #Específicamente:\n",
    "    #X_train: Transformar después de fit para que los datos de entrenamiento sean procesados correctamente.\n",
    "    #X_test: Transformar usando los parámetros aprendidos en X_train.\n",
    "#\n",
    "#fit_transform:\n",
    "\n",
    "    #Es un atajo para hacer fit seguido de transform.\n",
    "    #Se usa solo con X_train para ajustar y transformar los datos de una vez.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
