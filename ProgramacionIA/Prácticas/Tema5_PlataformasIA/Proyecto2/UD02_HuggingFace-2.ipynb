{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltzIxUYFNLrm"
   },
   "source": [
    "# Trabajando con pipelines de Hugging Face\n",
    "\n",
    "Los [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) son la forma más sencilla de utilizar modelos ya pre-entrenados.\n",
    "\n",
    "\n",
    "Soporta muchas funciones muy comunes como:\n",
    "\n",
    "**Text**:\n",
    "* Sentiment analysis: clasificar un texto dado por ejemplo diciendo si es toxico o no.\n",
    "* Text generation (in English): generar texto dando un input concreto.\n",
    "* Name entity recognition (NER): etiquetar cada palabra con una entidad que la representa como por ejemplo persona, fecha, localización, ...\n",
    "* Question answering: extraer una respuesta de un contexto dado, dado un contexto y una pregunta.\n",
    "* Fill-mask: rellenar un espacio en blanco dentro de un texto.\n",
    "* Summarization: generar resumenes de textos.\n",
    "* Translation: traducir texto a otro lenguaje.\n",
    "\n",
    "**Image**:\n",
    "* Image classification: clasificar una imagen\n",
    "* Image segmentation: clasificar cada pixel de una imagen.\n",
    "* Object detection: detectar objetos en una imagen.\n",
    "\n",
    "**Audio**:\n",
    "* Audio classification: asignar una etiqueta a un fragmento de audio.\n",
    "* Automatic speech recognition (ASR): transcribir audio a texto.\n",
    "\n",
    "<Tip>\n",
    "\n",
    "Para más detalles sobre [pipeline()](https://huggingface.co/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline) and sus tareas asociadas, puedes hacer clic [aqui](https://huggingface.co/docs/transformers/main/en/./main_classes/pipelines).\n",
    "\n",
    "</Tip>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_eLpjEyOmxc"
   },
   "source": [
    "## Instalar librerías\n",
    "\n",
    "En el siguiente código vemos como instalar las librerías necesarias para que llevar a cabo determinadas funcionalidades relacionadas con la Inteligencia Artificial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "w9Jm0s0JKHCI",
    "outputId": "1deeeb4d-e2d3-4705-93a7-0383fc718676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for torch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\andrei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\andrei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\andrei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\andrei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\andrei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\andrei\\appdata\\roaming\\python\\python313\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.4.5.tar.gz (65 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Checking for Rust toolchain....\n",
      "      \n",
      "      Cargo, the Rust package manager, is not installed or is not on PATH.\n",
      "      This package requires Rust and Cargo to compile extensions. Install it through\n",
      "      the system's package manager or via https://rustup.rs/\n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting diffusers\n",
      "  Using cached diffusers-0.31.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting importlib-metadata (from diffusers)\n",
      "  Using cached importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\andrei\\appdata\\roaming\\python\\python313\\site-packages (from diffusers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.2 in c:\\users\\andrei\\appdata\\roaming\\python\\python313\\site-packages (from diffusers) (0.26.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\andrei\\appdata\\roaming\\python\\python313\\site-packages (from diffusers) (2.1.2)\n",
      "Collecting regex!=2019.12.17 (from diffusers)\n",
      "  Using cached regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\andrei\\appdata\\roaming\\python\\python313\\site-packages (from diffusers) (2.32.3)\n",
      "Collecting safetensors>=0.3.1 (from diffusers)\n",
      "  Using cached safetensors-0.4.5.tar.gz (65 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Checking for Rust toolchain....\n",
      "      \n",
      "      Cargo, the Rust package manager, is not installed or is not on PATH.\n",
      "      This package requires Rust and Cargo to compile extensions. Install it through\n",
      "      the system's package manager or via https://rustup.rs/\n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Checking for Rust toolchain....\n",
      "      \n",
      "      Cargo, the Rust package manager, is not installed or is not on PATH.\n",
      "      This package requires Rust and Cargo to compile extensions. Install it through\n",
      "      the system's package manager or via https://rustup.rs/\n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting invisible_watermark\n",
      "  Using cached invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting safetensors\n",
      "  Using cached safetensors-0.4.5.tar.gz (65 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "#asegurarse que en la configuración del cuaderno está activada la GPU (para generación de imágenes)\n",
    "\n",
    "!pip install torch\n",
    "!pip install tensorflow\n",
    "!pip install transformers\n",
    "!pip install diffusers --upgrade\n",
    "!pip install invisible_watermark accelerate safetensors\n",
    "\n",
    "#reiniciar entorno después de instalarlas (Entorno de ejecución --> Reiniciar entorno de ejecución)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_feM46yKHCb"
   },
   "source": [
    "## Tareas comunes en IA utilizando pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpP-mwe1Pfbc"
   },
   "source": [
    "En primer lugar importo pipeline desde transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "UwK8bXq1Dhm-"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9D17L0b5omhJ"
   },
   "source": [
    "Construyo el clasificador como un pipeline. La utilización de pipeline será muy sencilla:\n",
    "\n",
    "\n",
    "```python\n",
    "inteligenciaArtificial = pipeline(task=\"<tarea>\", model=\"<modelo a utilizar>\")\n",
    "\n",
    "```\n",
    "\n",
    "*   **tarea** será la tarea que llevaremos a cabo;por ejemplo, text-generation, text-classification, audio-classification, ...\n",
    "*   **modelo a utilizar** puedes utilizar cualquier modelo de https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHovS0vlAfyG"
   },
   "source": [
    "### Generar texto acorde\n",
    "\n",
    "En este ejemplo veremos como generar texto acorde a una entrada, utilizaremos la tarea *text-generation* con el modelo *gpt2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvPnuSvf6JSx"
   },
   "outputs": [],
   "source": [
    "text_generator = pipeline(task=\"text-generation\", model=\"gpt2\")\n",
    "texto1=text_generator(\"My name is Carlos Saenz Adan and I'm teaching IA\")\n",
    "\n",
    "print(texto1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b37YV7wHAuyf"
   },
   "source": [
    "### Identificar imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrKW8miKIAdY"
   },
   "source": [
    "En primer lugar, lo que tengo que hacer es descargar una foto. En este caso es importante que se guarde con el nombre \"gato.jpg\" para que funcione el resto del código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEoTwKov_aFc"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "#si utilizas chrome\n",
    "#uploaded = files.upload()\n",
    "\n",
    "#descarga directa\n",
    "!wget -O ./gato.jpg https://st2.depositphotos.com/1814571/44220/i/1600/depositphotos_442208054-free-stock-photo-cute-sweet-little-gray-cat.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QleiyuDdIeUE"
   },
   "source": [
    "Utilizaremos la tarea *image-classification* con el modelo *microsoft/beit-base-patch16-224-pt22k-ft22k*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ev9nvJuX82Ly"
   },
   "outputs": [],
   "source": [
    "classify_image = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n",
    "classify_image(\"gato.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRlfJpckFXhE"
   },
   "source": [
    "### Preguntar sobre una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wekKH_5FD9Ov"
   },
   "outputs": [],
   "source": [
    "picture_question = pipeline(task=\"visual-question-answering\", model=\"dandelin/vilt-b32-finetuned-vqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axeBk_gyGNzM"
   },
   "outputs": [],
   "source": [
    "picture_question(image=\"gato.jpg\", question=\"is it the barcelona football team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cX3-eKbGmoB"
   },
   "outputs": [],
   "source": [
    "picture_question(image=\"gato.jpg\", question=\"is it the real madrid football team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ijIu9GOGplk"
   },
   "outputs": [],
   "source": [
    "picture_question(image=\"gato.jpg\", question=\"is it an animal?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PGZGpTKEJGjn"
   },
   "outputs": [],
   "source": [
    "picture_question(image=\"gato.jpg\", question=\"is it a dog?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FzpC120CpZXx"
   },
   "outputs": [],
   "source": [
    "picture_question(image=\"gato.jpg\", question=\"is it a human?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RroYw1FvpiCX"
   },
   "outputs": [],
   "source": [
    "picture_question(image=\"gato.jpg\", question=\"is it a human dressed as a cat?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxVN-VgXph2n"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oSgfMgzj2voY"
   },
   "source": [
    "### Describir una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WDDFBQLC2uqs"
   },
   "outputs": [],
   "source": [
    "clasificador = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-large\")\n",
    "texto1=clasificador(\"gato.jpg\")\n",
    "\n",
    "print(texto1[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yvrjBXtwkNW"
   },
   "source": [
    "### Generar una imagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYImaxw6XiHZ"
   },
   "source": [
    "Resource:\n",
    "https://huggingface.co/segmind/SSD-1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "889DuWaBUFOK"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2gacKM4-UExK"
   },
   "outputs": [],
   "source": [
    "!pip install transformers accelerate safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JRoiq87sUCbi"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'diffusers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdiffusers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StableDiffusionXLPipeline\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m StableDiffusionXLPipeline\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msegmind/SSD-1B\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16, use_safetensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, variant\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'diffusers'"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "import torch\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\"segmind/SSD-1B\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "pipe.to(\"cuda\")\n",
    "# if using torch < 2.0\n",
    "# pipe.enable_xformers_memory_efficient_attention()\n",
    "prompt = \"An astronaut riding a green horse\" # Your prompt here\n",
    "neg_prompt = \"ugly, blurry, poor quality\" # Negative prompt here\n",
    "image = pipe(prompt=prompt, negative_prompt=neg_prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GH8rneayWM23"
   },
   "outputs": [],
   "source": [
    "image.save(\"image.jpeg\") #guardo la imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cqJTAbQJWUwa"
   },
   "outputs": [],
   "source": [
    "prompt = \"A computer science teacher inside a class with students\" # Your prompt here\n",
    "neg_prompt = \"ugly, blurry, poor quality\" # Negative prompt here\n",
    "image = pipe(prompt=prompt, negative_prompt=neg_prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qG5wGVC_WYqg"
   },
   "outputs": [],
   "source": [
    "image.save(\"image2.jpeg\") #guardo la imagen"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
